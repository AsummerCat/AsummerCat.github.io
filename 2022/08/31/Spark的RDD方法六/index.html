<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/%E9%A3%9E%E5%A4%A9%E5%B0%8F%E5%A5%B3%E8%AD%A6_%E8%8A%B1%E8%8A%B1.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/%E9%A3%9E%E5%A4%A9%E5%B0%8F%E5%A5%B3%E8%AD%A6_%E8%8A%B1%E8%8A%B1.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.geekzu.org/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"www.linjingc.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="Spark的RDD方法1.Map将数据逐条做转换, 可以是类型的转换,也可以是值的转换 123456val dataRDD :RDD[Int] &#x3D; sparkContext.makeRDD(List(1,2,3,4))val dataRDD1 :RDD[Int]&#x3D; dataRDD.map(num &#x3D;&gt; &amp;#123; num &#x3D;num*2&amp;#125;)或者 val rdd1 &#x3D; sc.para"><meta property="og:type" content="article"><meta property="og:title" content="Spark的RDD方法六"><meta property="og:url" content="http://www.linjingc.top/2022/08/31/Spark%E7%9A%84RDD%E6%96%B9%E6%B3%95%E5%85%AD/index.html"><meta property="og:site_name" content="emmm读书使我快乐"><meta property="og:description" content="Spark的RDD方法1.Map将数据逐条做转换, 可以是类型的转换,也可以是值的转换 123456val dataRDD :RDD[Int] &#x3D; sparkContext.makeRDD(List(1,2,3,4))val dataRDD1 :RDD[Int]&#x3D; dataRDD.map(num &#x3D;&gt; &amp;#123; num &#x3D;num*2&amp;#125;)或者 val rdd1 &#x3D; sc.para"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2022-08-31T14:05:44.000Z"><meta property="article:modified_time" content="2023-12-06T03:17:10.806Z"><meta property="article:author" content="一只写Bug的猫"><meta property="article:tag" content="大数据"><meta property="article:tag" content="Spark"><meta name="twitter:card" content="summary"><link rel="canonical" href="http://www.linjingc.top/2022/08/31/Spark%E7%9A%84RDD%E6%96%B9%E6%B3%95%E5%85%AD/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://www.linjingc.top/2022/08/31/Spark%E7%9A%84RDD%E6%96%B9%E6%B3%95%E5%85%AD/","path":"2022/08/31/Spark的RDD方法六/","title":"Spark的RDD方法六"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Spark的RDD方法六 | emmm读书使我快乐</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">emmm读书使我快乐</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark%E7%9A%84RDD%E6%96%B9%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">Spark的RDD方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Map"><span class="nav-number">1.1.</span> <span class="nav-text">1.Map</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-mapPartitions"><span class="nav-number">1.2.</span> <span class="nav-text">2.mapPartitions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-mapPartitionsWithIndex"><span class="nav-number">1.3.</span> <span class="nav-text">3.mapPartitionsWithIndex</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-flatMap"><span class="nav-number">1.4.</span> <span class="nav-text">4.flatMap</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-glom-%E8%BD%AC%E6%8D%A2%E6%88%90%E6%95%B0%E7%BB%84"><span class="nav-number">1.5.</span> <span class="nav-text">5.glom 转换成数组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-groupBy"><span class="nav-number">1.6.</span> <span class="nav-text">6.groupBy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-filter"><span class="nav-number">1.7.</span> <span class="nav-text">7.filter</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-sample"><span class="nav-number">1.8.</span> <span class="nav-text">8.sample</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-distinct"><span class="nav-number">1.9.</span> <span class="nav-text">9.distinct</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-coalesce-%E5%8E%8B%E7%BC%A9%E5%90%88%E5%B9%B6%E5%88%86%E5%8C%BA-%E7%BC%A9%E5%87%8F%E5%88%86%E5%8C%BA"><span class="nav-number">1.10.</span> <span class="nav-text">10.coalesce 压缩合并分区 缩减分区</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-repartition-%E6%89%A9%E5%A4%A7%E5%88%86%E5%8C%BA"><span class="nav-number">1.11.</span> <span class="nav-text">11.repartition 扩大分区</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-sortBy"><span class="nav-number">1.12.</span> <span class="nav-text">12.sortBy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-intersection-%E5%90%88%E5%B9%B6%E5%A4%9A%E4%B8%AARDD-%E6%B1%82%E4%BA%A4%E9%9B%86"><span class="nav-number">1.13.</span> <span class="nav-text">13.intersection 合并多个RDD 求交集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#14-union-%E5%90%88%E5%B9%B6RDD%E5%8F%96%E5%B9%B6%E9%9B%86"><span class="nav-number">1.14.</span> <span class="nav-text">14.union 合并RDD取并集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#15-subtract-%E6%B1%82%E5%B7%AE%E9%9B%86"><span class="nav-number">1.15.</span> <span class="nav-text">15.subtract 求差集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#16-zip"><span class="nav-number">1.16.</span> <span class="nav-text">16.zip</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#17-partitionBy-%E6%A0%B9%E6%8D%AE%E5%88%86%E5%8C%BA%E9%87%8D%E6%96%B0%E5%88%86%E5%8C%BA%E6%8E%92%E5%88%97%E6%95%B0%E6%8D%AE"><span class="nav-number">1.17.</span> <span class="nav-text">17.partitionBy 根据分区重新分区排列数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#18-reduceByKey-%E6%80%A7%E8%83%BD%E6%AF%94groupByKey%E4%BC%98-%E5%88%86%E7%BB%84%E5%8A%A0%E8%81%9A%E5%90%88"><span class="nav-number">1.18.</span> <span class="nav-text">18.reduceByKey 性能比groupByKey优 (分组加聚合)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#19-groupByKey-%E4%BB%85%E5%88%86%E7%BB%84"><span class="nav-number">1.19.</span> <span class="nav-text">19.groupByKey (仅分组)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20-aggregateByKey"><span class="nav-number">1.20.</span> <span class="nav-text">20.aggregateByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#21-foldByKey"><span class="nav-number">1.21.</span> <span class="nav-text">21.foldByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#22-combineByKey"><span class="nav-number">1.22.</span> <span class="nav-text">22.combineByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#23-sortByKey"><span class="nav-number">1.23.</span> <span class="nav-text">23.sortByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#24-join"><span class="nav-number">1.24.</span> <span class="nav-text">24.join</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#25-leftOuterJoin"><span class="nav-number">1.25.</span> <span class="nav-text">25.leftOuterJoin</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#26-cogroup"><span class="nav-number">1.26.</span> <span class="nav-text">26.cogroup</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RDD-%E8%A1%8C%E5%8A%A8%E7%AE%97%E5%AD%90"><span class="nav-number">2.</span> <span class="nav-text">RDD 行动算子</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-reduce"><span class="nav-number">2.1.</span> <span class="nav-text">1.reduce</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-collect"><span class="nav-number">2.2.</span> <span class="nav-text">2.collect</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-count"><span class="nav-number">2.3.</span> <span class="nav-text">3.count</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-first"><span class="nav-number">2.4.</span> <span class="nav-text">4.first</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-take"><span class="nav-number">2.5.</span> <span class="nav-text">5.take</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-takeOrdered"><span class="nav-number">2.6.</span> <span class="nav-text">6.takeOrdered</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-aggregate"><span class="nav-number">2.7.</span> <span class="nav-text">7.aggregate</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-fold"><span class="nav-number">2.8.</span> <span class="nav-text">8.fold</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-countByKey"><span class="nav-number">2.9.</span> <span class="nav-text">9.countByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-save-%E7%9B%B8%E5%85%B3%E7%AE%97%E5%AD%90"><span class="nav-number">2.10.</span> <span class="nav-text">10.save 相关算子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-foreach"><span class="nav-number">2.11.</span> <span class="nav-text">11.foreach</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="一只写Bug的猫" src="/img/WechatIMG230.jpeg"><p class="site-author-name" itemprop="name">一只写Bug的猫</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">849</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">207</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://www.linjingc.top/2022/08/31/Spark%E7%9A%84RDD%E6%96%B9%E6%B3%95%E5%85%AD/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/WechatIMG230.jpeg"><meta itemprop="name" content="一只写Bug的猫"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="emmm读书使我快乐"><meta itemprop="description" content=""></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Spark的RDD方法六 | emmm读书使我快乐"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Spark的RDD方法六</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-08-31 14:05:44" itemprop="dateCreated datePublished" datetime="2022-08-31T14:05:44Z">2022-08-31</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-06 03:17:10" itemprop="dateModified" datetime="2023-12-06T03:17:10Z">2023-12-06</time> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.1k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="Spark的RDD方法"><a href="#Spark的RDD方法" class="headerlink" title="Spark的RDD方法"></a>Spark的RDD方法</h1><h2 id="1-Map"><a href="#1-Map" class="headerlink" title="1.Map"></a>1.Map</h2><p>将数据逐条做转换, 可以是类型的转换,也可以是值的转换</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD :RDD[Int] = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">val dataRDD1 :RDD[Int]= dataRDD.<span class="built_in">map</span>(<span class="built_in">num</span> =&gt; &#123; <span class="built_in">num</span> =<span class="built_in">num</span>*<span class="number">2</span>&#125;)</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"> val rdd1 = sc.parallelize(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>), <span class="number">2</span>).<span class="built_in">map</span>(<span class="symbol">_</span> * <span class="number">2</span>)</span><br><span class="line"> </span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="2-mapPartitions"><a href="#2-mapPartitions" class="headerlink" title="2.mapPartitions"></a>2.mapPartitions</h2><p>Map的升级版<br>以分区为单位处理数据<br>差别:</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Map</span> 算子主要目的将数据源中的数据进行转换和改变。但是不会减少或增多数据。 </span><br><span class="line">MapPartitions 算子需要传递一个迭代器，返回一个迭代器，没有要求的元素的个数保持不变，</span><br><span class="line">所以可以增加或减少数据</span><br></pre></td></tr></table></figure><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD1: RDD[Int] = dataRDD.mapPartitions(<span class="function"><span class="params">datas</span> =&gt;</span> &#123;datas.<span class="built_in">filter</span>(_==<span class="number">2</span>)&#125; )</span><br><span class="line"> </span><br><span class="line">或者</span><br><span class="line">分区内的数据都乘<span class="number">2</span></span><br><span class="line">val dataRDD1: RDD[Int] = dataRDD.mapPartitions(<span class="function"><span class="params">datas</span> =&gt;</span> &#123;datas.<span class="built_in">map</span>(_*<span class="number">2</span>)&#125;)</span><br></pre></td></tr></table></figure><h2 id="3-mapPartitionsWithIndex"><a href="#3-mapPartitionsWithIndex" class="headerlink" title="3.mapPartitionsWithIndex"></a>3.mapPartitionsWithIndex</h2><p>在处理时同时可以获取当前分区索引。</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD1 = dataRDD.mapPartitionsWithIndex(</span><br><span class="line"><span class="comment">//分区号,迭代器</span></span><br><span class="line"> (<span class="keyword">index</span>, datas) =&gt; &#123;</span><br><span class="line"> datas.map(<span class="keyword">index</span>, _)</span><br><span class="line"> &#125; )</span><br></pre></td></tr></table></figure><h2 id="4-flatMap"><a href="#4-flatMap" class="headerlink" title="4.flatMap"></a>4.flatMap</h2><p>将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD = sparkContext<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">2</span>),<span class="built_in">List</span>(<span class="number">3</span>,<span class="number">4</span>)),<span class="number">1</span>)</span><br><span class="line">val dataRDD1 = dataRDD<span class="selector-class">.flatMap</span>(list =&gt; list)</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line">将字符按照空格切分 并且输出</span><br><span class="line">val dataRDD = sparkContext<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="string">&quot;hello word&quot;</span>, <span class="string">&quot;hello Words&quot;</span>),<span class="number">1</span>)</span><br><span class="line">val dataRDD1 = dataRDD<span class="selector-class">.flatMap</span>(</span><br><span class="line"> s =&gt; &#123;</span><br><span class="line">     s<span class="selector-class">.split</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="5-glom-转换成数组"><a href="#5-glom-转换成数组" class="headerlink" title="5.glom 转换成数组"></a>5.glom 转换成数组</h2><p>将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">1</span>)</span><br><span class="line"><span class="attribute">val</span> dataRDD1:RDD[Array[Int]] = dataRDD.glom()</span><br></pre></td></tr></table></figure><h2 id="6-groupBy"><a href="#6-groupBy" class="headerlink" title="6.groupBy"></a>6.groupBy</h2><p>将数据根据指定的规则进行分组,分区默认不变，但是数据会被打乱重新组合</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">1</span>)</span><br><span class="line"><span class="attribute">val</span> dataRDD1 = dataRDD.groupBy(_%<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="7-filter"><a href="#7-filter" class="headerlink" title="7.filter"></a>7.filter</h2><p>将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">1</span>)</span><br><span class="line"><span class="attribute">val</span> dataRDD1 = dataRDD.filter(_%<span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="8-sample"><a href="#8-sample" class="headerlink" title="8.sample"></a>8.sample</h2><p>根据指定的规则从数据集中抽取数据</p><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD <span class="operator">=</span> sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 抽取数据不放回（伯努利算法）</span></span><br><span class="line"><span class="comment">// 伯努利算法：又叫 0、1 分布。例如扔硬币，要么正面，要么反面。</span></span><br><span class="line"><span class="comment">// 具体实现：根据种子和随机算法算出一个数和第二个参数设置几率比较，小于第二个参数要，大于不</span></span><br><span class="line">要</span><br><span class="line"><span class="comment">// 第一个参数：抽取的数据是否放回，false：不放回</span></span><br><span class="line"><span class="comment">// 第二个参数：抽取的几率，范围在[0,1]之间,0：全不取；1：全取；</span></span><br><span class="line"><span class="comment">// 第三个参数：随机数种子</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 <span class="operator">=</span> dataRDD.sample(<span class="literal">false</span>, <span class="number">0.5</span>)</span><br><span class="line"><span class="comment">// 抽取数据放回（泊松算法）</span></span><br><span class="line"><span class="comment">// 第一个参数：抽取的数据是否放回，true：放回；false：不放回</span></span><br><span class="line"><span class="comment">// 第二个参数：重复数据的几率，范围大于等于 0.表示每一个元素被期望抽取到的次数</span></span><br><span class="line"><span class="comment">// 第三个参数：随机数种子</span></span><br><span class="line"><span class="keyword">val</span> dataRDD2 <span class="operator">=</span> dataRDD.sample(<span class="literal">true</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="9-distinct"><a href="#9-distinct" class="headerlink" title="9.distinct"></a>9.distinct</h2><p>将数据集中重复的数据去重</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),<span class="number">1</span>)</span><br><span class="line"><span class="attribute">val</span> dataRDD1 = dataRDD.distinct()</span><br></pre></td></tr></table></figure><h2 id="10-coalesce-压缩合并分区-缩减分区"><a href="#10-coalesce-压缩合并分区-缩减分区" class="headerlink" title="10.coalesce 压缩合并分区 缩减分区"></a>10.coalesce 压缩合并分区 缩减分区</h2><p>根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率</p><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD <span class="operator">=</span> sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//默认情况下,不会将原先的分区进行打散处理</span></span><br><span class="line"><span class="comment">//如需打乱-&gt;加入第二个参数 ture</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 <span class="operator">=</span> dataRDD.coalesce(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 <span class="operator">=</span> dataRDD.coalesce(<span class="number">2</span>,<span class="literal">true</span>)</span><br></pre></td></tr></table></figure><h2 id="11-repartition-扩大分区"><a href="#11-repartition-扩大分区" class="headerlink" title="11.repartition 扩大分区"></a>11.repartition 扩大分区</h2><p>该操作内部其实执行的是 coalesce 操作</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),<span class="number">2</span>)</span><br><span class="line"><span class="attribute">val</span> dataRDD1 = dataRDD.repartition(<span class="number">4</span>)</span><br></pre></td></tr></table></figure><h2 id="12-sortBy"><a href="#12-sortBy" class="headerlink" title="12.sortBy"></a>12.sortBy</h2><p>该操作用于排序数据</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD = sparkContext.makeRDD(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>),<span class="number">2</span>)</span><br><span class="line"><span class="comment">//sortBy 默认升序</span></span><br><span class="line">val dataRDD1 = dataRDD.sortBy(<span class="built_in">num</span>=&gt;<span class="built_in">num</span>)</span><br><span class="line"><span class="comment">//sortBy 第二个参数表示降序</span></span><br><span class="line">val dataRDD1 = dataRDD.sortBy(<span class="built_in">num</span>=&gt;<span class="built_in">num</span>, <span class="keyword">false</span>)</span><br></pre></td></tr></table></figure><h2 id="13-intersection-合并多个RDD-求交集"><a href="#13-intersection-合并多个RDD-求交集" class="headerlink" title="13.intersection 合并多个RDD 求交集"></a>13.intersection 合并多个RDD 求交集</h2><p>对源 RDD 和参数 RDD 求交集后返回一个新的 RDD</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = sparkContext.makeRDD(List(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD = dataRDD1.intersection(dataRDD2)</span><br></pre></td></tr></table></figure><h2 id="14-union-合并RDD取并集"><a href="#14-union-合并RDD取并集" class="headerlink" title="14.union  合并RDD取并集"></a>14.union 合并RDD取并集</h2><p>对源 RDD 和参数 RDD 求并集后返回一个新的 RDD</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = sparkContext.makeRDD(List(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD = dataRDD1.union(dataRDD2)</span><br></pre></td></tr></table></figure><h2 id="15-subtract-求差集"><a href="#15-subtract-求差集" class="headerlink" title="15.subtract 求差集"></a>15.subtract 求差集</h2><p>以一个 RDD 元素为主，去除两个 RDD 中重复元素，将其他元素保留下来。求差集</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = sparkContext.makeRDD(List(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD = dataRDD1.subtract(dataRDD2)</span><br></pre></td></tr></table></figure><h2 id="16-zip"><a href="#16-zip" class="headerlink" title="16.zip"></a>16.zip</h2><p>将两个 RDD 中的元素，以键值对的形式进行合并。其中，键值对中的 Key 为第 1 个 RDD<br>中的元素，Value 为第 2 个 RDD 中的相同位置的元素</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = sparkContext.makeRDD(List(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="attribute">val</span> dataRDD = dataRDD1.zip(dataRDD2)</span><br></pre></td></tr></table></figure><h2 id="17-partitionBy-根据分区重新分区排列数据"><a href="#17-partitionBy-根据分区重新分区排列数据" class="headerlink" title="17.partitionBy  根据分区重新分区排列数据"></a>17.partitionBy 根据分区重新分区排列数据</h2><p>将数据按照指定 Partitioner 重新进行分区。Spark 默认的分区器是 HashPartitioner</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.HashPartitioner</span></span><br><span class="line"></span><br><span class="line">val rdd: RDD<span class="selector-attr">[(Int, String)]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">Array</span>((<span class="number">1</span>,<span class="string">&quot;aaa&quot;</span>),(<span class="number">2</span>,<span class="string">&quot;bbb&quot;</span>),(<span class="number">3</span>,<span class="string">&quot;ccc&quot;</span>)),<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">val rdd2: RDD<span class="selector-attr">[(Int, String)]</span> =rdd<span class="selector-class">.partitionBy</span>(new <span class="built_in">HashPartitioner</span>(<span class="number">2</span>))</span><br></pre></td></tr></table></figure><h2 id="18-reduceByKey-性能比groupByKey优-分组加聚合"><a href="#18-reduceByKey-性能比groupByKey优-分组加聚合" class="headerlink" title="18.reduceByKey 性能比groupByKey优 (分组加聚合)"></a>18.reduceByKey 性能比groupByKey优 (分组加聚合)</h2><p>可以将数据按照相同的 Key 对 Value 进行聚合,<br>如果key只有一个不参与计算</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = dataRDD1.reduceByKey(_+_)</span><br><span class="line"><span class="attribute">val</span> dataRDD3 = dataRDD1.reduceByKey(_+_, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="19-groupByKey-仅分组"><a href="#19-groupByKey-仅分组" class="headerlink" title="19.groupByKey (仅分组)"></a>19.groupByKey (仅分组)</h2><p>将数据源的数据根据 key 对 value 进行分组</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD1 =</span><br><span class="line"> sparkContext<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line">val dataRDD2 = dataRDD1<span class="selector-class">.groupByKey</span>()</span><br><span class="line">val dataRDD3 = dataRDD1<span class="selector-class">.groupByKey</span>(<span class="number">2</span>)</span><br><span class="line">val dataRDD4 = dataRDD1<span class="selector-class">.groupByKey</span>(new <span class="built_in">HashPartitioner</span>(<span class="number">2</span>))</span><br></pre></td></tr></table></figure><h2 id="20-aggregateByKey"><a href="#20-aggregateByKey" class="headerlink" title="20.aggregateByKey"></a>20.aggregateByKey</h2><p>将数据根据不同的规则进行分区内计算和分区间计算</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = dataRDD1.aggregateByKey(<span class="number">0</span>)(_+_,_+_)</span><br></pre></td></tr></table></figure><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TODO : 取出每个分区内相同 key 的最大值然后分区间相加</span></span><br><span class="line"><span class="comment">// aggregateByKey 算子是函数柯里化，存在两个参数列表</span></span><br><span class="line"><span class="comment">// 1. 第一个参数列表中的参数表示初始值</span></span><br><span class="line"><span class="comment">// 2. 第二个参数列表中含有两个参数</span></span><br><span class="line"><span class="comment">// 2.1 第一个参数表示分区内的计算规则</span></span><br><span class="line"><span class="comment">// 2.2 第二个参数表示分区间的计算规则</span></span><br><span class="line">val rdd =</span><br><span class="line"> sc.makeRDD<span class="comment">(List(</span></span><br><span class="line"><span class="comment"> (&quot;a&quot;,1)</span>,<span class="comment">(&quot;a&quot;,2)</span>,<span class="comment">(&quot;c&quot;,3)</span>,</span><br><span class="line"> <span class="comment">(&quot;b&quot;,4)</span>,<span class="comment">(&quot;c&quot;,5)</span>,<span class="comment">(&quot;c&quot;,6)</span></span><br><span class="line"> ),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//第一个参数是初始化值 ,用于默认比较的值</span></span><br><span class="line">val resultRDD =</span><br><span class="line"> rdd.aggregateByKey<span class="comment">(10)</span><span class="comment">(</span></span><br><span class="line"><span class="comment"> (x, y)</span> =&gt; math.max<span class="comment">(x,y)</span>,</span><br><span class="line"> <span class="comment">(x, y)</span> =&gt; x + y</span><br><span class="line"> )</span><br><span class="line">resultRDD.collect<span class="comment">()</span>.foreach<span class="comment">(println)</span></span><br></pre></td></tr></table></figure><h2 id="21-foldByKey"><a href="#21-foldByKey" class="headerlink" title="21.foldByKey"></a>21.foldByKey</h2><p>当分区内计算规则和分区间计算规则相同时，aggregateByKey 就可以简化为 foldByKey</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = dataRDD1.foldByKey(<span class="number">0</span>)(_+_)</span><br></pre></td></tr></table></figure><h2 id="22-combineByKey"><a href="#22-combineByKey" class="headerlink" title="22.combineByKey"></a>22.combineByKey</h2><p>将参与计算的第一个参数进行结构转换作为初始值计算,其他逻辑跟aggregateByKey一致</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val combineRdd: RDD[(<span class="built_in">String</span>, (Int, Int))] = input.combineByKey(</span><br><span class="line"> (_, <span class="number">1</span>),</span><br><span class="line"> <span class="function"><span class="params">(acc: (Int, Int), v)</span> =&gt;</span> (acc._1 + v, acc._2+ <span class="number">1</span>),</span><br><span class="line"> <span class="function"><span class="params">(acc1: (Int, Int), acc2: (Int, Int))</span> =&gt;</span> (acc1._1 + acc2._1, acc1._2 + acc2._2)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>AggregateByKey</code>：相同 key 的第一个数据和初始值进行分区内计算，分区内和分区间计算规<br>则可以不相同<br><code>CombineByKey</code>:当计算时，发现数据结构不满足要求时，可以让第一个数据转换结构。分区<br>内和分区间计算规则不相同</p><h2 id="23-sortByKey"><a href="#23-sortByKey" class="headerlink" title="23.sortByKey"></a>23.sortByKey</h2><p>在一个(K,V)的 RDD 上调用，K 必须实现 Ordered 接口(特质)，返回一个按照 key 进行排序<br>的</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(List((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> sortRDD1: RDD[(String, <span class="built_in">Int</span>)] = dataRDD1.sortByKey(<span class="literal">true</span>)</span><br><span class="line"><span class="keyword">val</span> sortRDD1: RDD[(String, <span class="built_in">Int</span>)] = dataRDD1.sortByKey(<span class="literal">false</span>)</span><br></pre></td></tr></table></figure><h2 id="24-join"><a href="#24-join" class="headerlink" title="24.join"></a>24.join</h2><p>在类型为(K,V)和(K,W)的 RDD 上调用，返回一个相同 key 对应的所有元素连接在一起的</p><p>ps: 如果两个数据源key有多个相同可能会出现笛卡尔积</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> rdd: RDD[(Int, String)] = sc.makeRDD(Array((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, <span class="string">&quot;b&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)))</span><br><span class="line"><span class="attribute">val</span> rdd1: RDD[(Int, Int)] = sc.makeRDD(Array((<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)))</span><br><span class="line"><span class="attribute">rdd</span>.join(rdd1).collect().foreach(println)</span><br></pre></td></tr></table></figure><h2 id="25-leftOuterJoin"><a href="#25-leftOuterJoin" class="headerlink" title="25.leftOuterJoin"></a>25.leftOuterJoin</h2><p>类似于 SQL 语句的左外连接</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> dataRDD1 = sparkContext.makeRDD(List((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="attribute">val</span> dataRDD2 = sparkContext.makeRDD(List((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="attribute">val</span> rdd: RDD[(String, (Int, Option[Int]))] = dataRDD1.leftOuterJoin(dataRDD2)</span><br></pre></td></tr></table></figure><h2 id="26-cogroup"><a href="#26-cogroup" class="headerlink" title="26.cogroup"></a>26.cogroup</h2><p>在类型为(K,V)和(K,W)的 RDD 上调用，返回一个(K,(Iterable<v>,Iterable<w>))类型的 RDD</w></v></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val dataRDD1 = sparkContext<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line">val dataRDD2 = sparkContext<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line">val value: RDD<span class="selector-attr">[(String, (Iterable[Int]</span>, Iterable<span class="selector-attr">[Int]</span>))] = dataRDD1<span class="selector-class">.cogroup</span>(dataRDD2)</span><br></pre></td></tr></table></figure><h1 id="RDD-行动算子"><a href="#RDD-行动算子" class="headerlink" title="RDD 行动算子"></a>RDD 行动算子</h1><h2 id="1-reduce"><a href="#1-reduce" class="headerlink" title="1.reduce"></a>1.reduce</h2><p>聚集 RDD 中的所有元素，先聚合分区内数据，再聚合分区间数据</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: RDD[<span class="built_in">Int</span>] = sc.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 聚合数据</span></span><br><span class="line"><span class="keyword">val</span> reduceResult: <span class="built_in">Int</span> = rdd.reduce(_+_)</span><br></pre></td></tr></table></figure><h2 id="2-collect"><a href="#2-collect" class="headerlink" title="2.collect"></a>2.collect</h2><p>在驱动程序中，以数组 Array 的形式返回数据集的所有元素</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val rdd: RDD<span class="selector-attr">[Int]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 收集数据到 Driver</span></span><br><span class="line">rdd<span class="selector-class">.collect</span>()<span class="selector-class">.foreach</span>(println)</span><br></pre></td></tr></table></figure><h2 id="3-count"><a href="#3-count" class="headerlink" title="3.count"></a>3.count</h2><p>返回 RDD 中元素的个数</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: RDD[<span class="built_in">Int</span>] = sc.makeRDD(List(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> countResult: <span class="built_in">Long</span> = rdd.count()</span><br></pre></td></tr></table></figure><h2 id="4-first"><a href="#4-first" class="headerlink" title="4.first"></a>4.first</h2><p>返回 RDD 中的第一个元素</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd: RDD<span class="selector-attr">[Int]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line">val firstResult: Int = rdd<span class="selector-class">.first</span>()</span><br><span class="line"><span class="function"><span class="title">println</span><span class="params">(firstResult)</span></span></span><br></pre></td></tr></table></figure><h2 id="5-take"><a href="#5-take" class="headerlink" title="5.take"></a>5.take</h2><p>返回一个由 RDD 的前 n 个元素组成的数组</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vval rdd: RDD<span class="selector-attr">[Int]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line">val takeResult: Array<span class="selector-attr">[Int]</span> = rdd<span class="selector-class">.take</span>(<span class="number">2</span>)</span><br><span class="line"><span class="function"><span class="title">println</span><span class="params">(takeResult.mkString(<span class="string">&quot;,&quot;</span>)</span></span>)</span><br></pre></td></tr></table></figure><h2 id="6-takeOrdered"><a href="#6-takeOrdered" class="headerlink" title="6.takeOrdered"></a>6.takeOrdered</h2><p>返回该 RDD 排序后的前 n 个元素组成的数组</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val rdd: RDD<span class="selector-attr">[Int]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line">val result: Array<span class="selector-attr">[Int]</span> = rdd<span class="selector-class">.takeOrdered</span>(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="7-aggregate"><a href="#7-aggregate" class="headerlink" title="7.aggregate"></a>7.aggregate</h2><p>分区的数据通过初始值和分区内的数据进行聚合，然后再和初始值进行分区间的数据聚合</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd: <span class="type">RDD</span>[<span class="keyword">Int</span>] = sc.makeRDD(List(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">8</span>)</span><br><span class="line"><span class="comment">// 将该 RDD 所有元素相加得到结果</span></span><br><span class="line"><span class="comment">//val result: Int = rdd.aggregate(0)(_ + _, _ + _)</span></span><br><span class="line">val result: <span class="type">Int </span>= rdd.aggregate(<span class="number">10</span>)(<span class="literal">_</span> + <span class="literal">_</span>, <span class="literal">_</span> + <span class="literal">_</span>)</span><br></pre></td></tr></table></figure><h2 id="8-fold"><a href="#8-fold" class="headerlink" title="8.fold"></a>8.fold</h2><p>折叠操作，aggregate 的简化版操作</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">val</span> rdd: RDD[Int] = sc.makeRDD(List(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="attribute">val</span> foldResult: Int = rdd.fold(<span class="number">0</span>)(_+_)</span><br></pre></td></tr></table></figure><h2 id="9-countByKey"><a href="#9-countByKey" class="headerlink" title="9.countByKey"></a>9.countByKey</h2><p>统计每种 key 的个数</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd: RDD<span class="selector-attr">[(Int, String)]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">2</span>, </span><br><span class="line"><span class="string">&quot;b&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>), (<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)))</span><br><span class="line"><span class="comment">// 统计每种 key 的个数</span></span><br><span class="line">val result: collection<span class="selector-class">.Map</span><span class="selector-attr">[Int, Long]</span> = rdd<span class="selector-class">.countByKey</span>()</span><br></pre></td></tr></table></figure><h2 id="10-save-相关算子"><a href="#10-save-相关算子" class="headerlink" title="10.save 相关算子"></a>10.save 相关算子</h2><p>将数据保存到不同格式的文件中</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 保存成 Text 文件</span></span><br><span class="line">rdd<span class="selector-class">.saveAsTextFile</span>(<span class="string">&quot;output&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列化成对象保存到文件</span></span><br><span class="line">rdd<span class="selector-class">.saveAsObjectFile</span>(<span class="string">&quot;output1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 保存成 Sequencefile 文件</span></span><br><span class="line">rdd<span class="selector-class">.map</span>((_,<span class="number">1</span>))<span class="selector-class">.saveAsSequenceFile</span>(<span class="string">&quot;output2&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="11-foreach"><a href="#11-foreach" class="headerlink" title="11.foreach"></a>11.foreach</h2><p>分布式遍历 RDD 中的每一个元素，调用指定函数</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val rdd: RDD<span class="selector-attr">[Int]</span> = sc<span class="selector-class">.makeRDD</span>(<span class="built_in">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 收集后打印</span></span><br><span class="line">rdd<span class="selector-class">.map</span>(num=&gt;num)<span class="selector-class">.collect</span>()<span class="selector-class">.foreach</span>(println)</span><br><span class="line"><span class="function"><span class="title">println</span><span class="params">(<span class="string">&quot;****************&quot;</span>)</span></span></span><br><span class="line"><span class="comment">// 分布式打印</span></span><br><span class="line">rdd<span class="selector-class">.foreach</span>(println)</span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-tags"><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a> <a href="/tags/Spark/" rel="tag"># Spark</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2022/08/31/Spark%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E4%B9%8BRDD%E4%BA%94/" rel="prev" title="Spark核心内容之RDD五"><i class="fa fa-angle-left"></i> Spark核心内容之RDD五</a></div><div class="post-nav-item"><a href="/2022/08/31/Spark%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%83/" rel="next" title="Spark序列化七">Spark序列化七 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">一只写Bug的猫</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">2.7m</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">41:32</span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div></div></footer><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a href="https://github.com/AsummerCat/AsmmerCatHexo" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script><script>var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();</script></body></html>